digraph {
	graph [size="22.2,22.2"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2078555331760 [label="
 ()" fillcolor=darkolivegreen1]
	2078515070432 [label=MeanBackward0]
	2078515084592 -> 2078515070432
	2078515084592 [label=ViewBackward0]
	2078515079744 -> 2078515084592
	2078515079744 [label=MeanBackward1]
	2078515069520 -> 2078515079744
	2078515069520 [label=AddBackward0]
	2078515082576 -> 2078515069520
	2078515082576 [label=AddBackward0]
	2078515081616 -> 2078515082576
	2078515081616 [label=HardtanhBackward0]
	2078515073744 -> 2078515081616
	2078515073744 [label=CudnnBatchNormBackward0]
	2078515070048 -> 2078515073744
	2078515070048 [label=ConvolutionBackward0]
	2078515083872 -> 2078515070048
	2078515083872 [label=AddBackward0]
	2078515082048 -> 2078515083872
	2078515082048 [label=MaxPool2DWithIndicesBackward0]
	2078515083776 -> 2078515082048
	2078515083776 [label=AddBackward0]
	2078515080272 -> 2078515083776
	2078515080272 [label=LeakyReluBackward0]
	2078515080848 -> 2078515080272
	2078515080848 [label=CudnnBatchNormBackward0]
	2078515084832 -> 2078515080848
	2078515084832 [label=ConvolutionBackward0]
	2078515080416 -> 2078515084832
	2078515080416 [label=AddBackward0]
	2078515080608 -> 2078515080416
	2078515080608 [label=LeakyReluBackward0]
	2078515084016 -> 2078515080608
	2078515084016 [label=CudnnBatchNormBackward0]
	2078515070144 -> 2078515084016
	2078515070144 [label=ConvolutionBackward0]
	2078515084928 -> 2078515070144
	2078515084928 [label=MaxPool2DWithIndicesBackward0]
	2078515075712 -> 2078515084928
	2078515075712 [label=LeakyReluBackward0]
	2078515079264 -> 2078515075712
	2078515079264 [label=CudnnBatchNormBackward0]
	2078515077056 -> 2078515079264
	2078515077056 [label=ConvolutionBackward0]
	2078515078592 -> 2078515077056
	2078553711344 [label="conv1.weight
 (16, 3, 7, 7)" fillcolor=lightblue]
	2078553711344 -> 2078515078592
	2078515078592 [label=AccumulateGrad]
	2078515071920 -> 2078515077056
	2077762085296 [label="conv1.bias
 (16)" fillcolor=lightblue]
	2077762085296 -> 2078515071920
	2078515071920 [label=AccumulateGrad]
	2078515081808 -> 2078515079264
	2077762084496 [label="bn1.weight
 (16)" fillcolor=lightblue]
	2077762084496 -> 2078515081808
	2078515081808 [label=AccumulateGrad]
	2078515076672 -> 2078515079264
	2077762084416 [label="bn1.bias
 (16)" fillcolor=lightblue]
	2077762084416 -> 2078515076672
	2078515076672 [label=AccumulateGrad]
	2078515078016 -> 2078515070144
	2077762090896 [label="conv2.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	2077762090896 -> 2078515078016
	2078515078016 [label=AccumulateGrad]
	2078515085072 -> 2078515070144
	2077762090816 [label="conv2.bias
 (32)" fillcolor=lightblue]
	2077762090816 -> 2078515085072
	2078515085072 [label=AccumulateGrad]
	2078515069808 -> 2078515084016
	2077762084256 [label="bn2.weight
 (32)" fillcolor=lightblue]
	2077762084256 -> 2078515069808
	2078515069808 [label=AccumulateGrad]
	2078515079552 -> 2078515084016
	2077762084016 [label="bn2.bias
 (32)" fillcolor=lightblue]
	2077762084016 -> 2078515079552
	2078515079552 [label=AccumulateGrad]
	2078515081136 -> 2078515080416
	2078515081136 [label=ConvolutionBackward0]
	2078515084928 -> 2078515081136
	2078515074176 -> 2078515081136
	2078555297712 [label="residual_conv2.weight
 (32, 16, 1, 1)" fillcolor=lightblue]
	2078555297712 -> 2078515074176
	2078515074176 [label=AccumulateGrad]
	2078515070912 -> 2078515084832
	2077762134688 [label="conv3.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	2077762134688 -> 2078515070912
	2078515070912 [label=AccumulateGrad]
	2078515082144 -> 2078515084832
	2077762127968 [label="conv3.bias
 (64)" fillcolor=lightblue]
	2077762127968 -> 2078515082144
	2078515082144 [label=AccumulateGrad]
	2078515079216 -> 2078515080848
	2077762133968 [label="bn3.weight
 (64)" fillcolor=lightblue]
	2077762133968 -> 2078515079216
	2078515079216 [label=AccumulateGrad]
	2078515074128 -> 2078515080848
	2077762134208 [label="bn3.bias
 (64)" fillcolor=lightblue]
	2077762134208 -> 2078515074128
	2078515074128 [label=AccumulateGrad]
	2078515082624 -> 2078515083776
	2078515082624 [label=ConvolutionBackward0]
	2078515080416 -> 2078515082624
	2078515072352 -> 2078515082624
	2077762135168 [label="residual_conv3.weight
 (64, 32, 1, 1)" fillcolor=lightblue]
	2077762135168 -> 2078515072352
	2078515072352 [label=AccumulateGrad]
	2078515071488 -> 2078515083872
	2078515071488 [label=MaxPool2DWithIndicesBackward0]
	2078515083584 -> 2078515071488
	2078515083584 [label=MaxPool2DWithIndicesBackward0]
	2078515076096 -> 2078515083584
	2078515076096 [label=ConvolutionBackward0]
	2078515075712 -> 2078515076096
	2078515075424 -> 2078515076096
	2077762127808 [label="skip1x1_1to3.0.weight
 (64, 16, 1, 1)" fillcolor=lightblue]
	2077762127808 -> 2078515075424
	2078515075424 [label=AccumulateGrad]
	2078515071632 -> 2078515070048
	2077762133888 [label="conv4.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2077762133888 -> 2078515071632
	2078515071632 [label=AccumulateGrad]
	2078515079648 -> 2078515070048
	2077762135088 [label="conv4.bias
 (128)" fillcolor=lightblue]
	2077762135088 -> 2078515079648
	2078515079648 [label=AccumulateGrad]
	2078515080704 -> 2078515073744
	2077762134928 [label="bn4.weight
 (128)" fillcolor=lightblue]
	2077762134928 -> 2078515080704
	2078515080704 [label=AccumulateGrad]
	2078515072592 -> 2078515073744
	2077762128048 [label="bn4.bias
 (128)" fillcolor=lightblue]
	2077762128048 -> 2078515072592
	2078515072592 [label=AccumulateGrad]
	2078515078064 -> 2078515082576
	2078515078064 [label=ConvolutionBackward0]
	2078515083872 -> 2078515078064
	2078515080368 -> 2078515078064
	2077762127408 [label="residual_conv4.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2077762127408 -> 2078515080368
	2078515080368 [label=AccumulateGrad]
	2078515070288 -> 2078515069520
	2078515070288 [label=ConvolutionBackward0]
	2078515082048 -> 2078515070288
	2078515077920 -> 2078515070288
	2077762126928 [label="skip1x1_3to5.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2077762126928 -> 2078515077920
	2078515077920 [label=AccumulateGrad]
	2078515070432 -> 2078555331760
}
