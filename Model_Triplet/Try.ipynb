{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "\n",
    "        for img_name in os.listdir(root_dir):\n",
    "            img_path = os.path.join(root_dir, img_name)\n",
    "            if os.path.isfile(img_path) and img_path.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'tiff')):\n",
    "                self.image_paths.append(img_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, img_path\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)),transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])\n",
    "\n",
    "root_dir = r\"D:\\Computer Vision\\FYP\\TASK 1\\env\\TrackNet-X\\DataSet\\VeRi\\image_train\"\n",
    "\n",
    "dataset = ImageFolderDataset(root_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 0001_c001_00016450_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c001_00016460_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c001_00016470_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c001_00016480_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c001_00016490_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c001_00016500_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c002_00016885_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c002_00016895_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c002_00016905_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c002_00016915_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c002_00016945_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c002_00016955_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c012_00014680_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c012_00014685_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c012_00014690_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c012_00014695_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c012_00014700_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c012_00014705_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c013_00014770_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c013_00014790_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c013_00014800_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c013_00014810_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c013_00014815_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c013_00014825_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c014_00013130_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c014_00013135_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c014_00013140_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c014_00013145_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c014_00013150_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c014_00013175_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c015_00013200_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c015_00013205_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c015_00013210_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c015_00013215_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c015_00013220_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c015_00013225_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c016_00012920_1.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c016_00012925_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c016_00012930_1.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c016_00012935_1.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c016_00012940_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c016_00012945_1.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c017_00014060_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c017_00014075_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c017_00014085_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c017_00014100_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c017_00014115_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c017_00014130_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c019_00013820_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c019_00013825_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c019_00013830_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c019_00013835_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c019_00013845_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0001_c019_00013850_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c001_00021480_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c001_00021495_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c001_00021505_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c001_00021515_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c001_00021525_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c001_00021535_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c012_00020455_1.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c012_00020460_1.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c012_00020470_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c012_00020480_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c012_00020485_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c012_00020495_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c013_00020540_1.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c013_00020550_1.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c013_00020555_1.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c013_00020570_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c013_00020580_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c013_00020595_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c014_00018685_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c014_00018695_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c014_00018705_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c014_00018725_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c014_00018740_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c014_00018755_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c015_00018755_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c015_00018760_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c015_00018765_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c015_00018770_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c015_00018775_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c015_00018785_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c016_00018460_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c016_00018465_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c016_00018470_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c016_00018475_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c016_00018530_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c016_00018535_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c017_00019715_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c017_00019740_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c017_00019750_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c017_00019760_1.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c017_00019775_1.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c017_00019790_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c019_00019495_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c019_00019500_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c019_00019505_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c019_00019510_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c019_00019515_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0003_c019_00019530_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0004_c001_00043970_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0004_c001_00043980_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0004_c001_00043990_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0004_c001_00044000_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0004_c001_00044010_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0004_c001_00044020_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0004_c012_00044410_1.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0004_c012_00044415_1.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0004_c012_00044420_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0004_c012_00044425_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0004_c012_00044430_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0004_c012_00044435_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0004_c013_00044260_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0004_c013_00044265_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0004_c013_00044275_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0004_c013_00044285_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0004_c013_00044295_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c014_00049785_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c014_00049790_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c014_00049795_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c014_00049800_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c014_00049805_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c014_00049810_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c015_00049565_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c015_00049570_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c015_00049575_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c015_00049580_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c015_00049585_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c015_00049590_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c016_00050060_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c016_00050065_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c016_00050070_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c017_00047200_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c017_00047210_1.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c017_00047260_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c017_00047285_1.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c017_00047330_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c017_00047390_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c017_00048130_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c017_00048135_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c017_00048145_0.jpg, Image shape: torch.Size([3, 224, 224])\n",
      "Name: 0007_c017_00048195_0.jpg, Image shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for idx in range(144):\n",
    "    image, img_path = dataset[idx]\n",
    "    print(f\"Name: {os.path.basename(img_path)}, Image shape: {image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "\n",
    "        # First convolution layer: 7x7 kernel, stride 5, padding 3, 12 channels\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=7, stride=5, padding=3)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=1)  # No downsampling here\n",
    "\n",
    "        # Second convolution layer: 3x3 kernel, stride 1, padding 1, 24 channels\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Third convolution layer: 3x3 kernel, stride 1, padding 1, 32 channels (no downsampling)\n",
    "        self.conv3 = nn.Conv2d(in_channels=24, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # Reduces to 32x32\n",
    "\n",
    "        # Fourth convolution layer: 3x3 kernel, stride 1, padding 1, 64 channels (no downsampling)\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Adaptive pooling to prevent size issues\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = F.relu(self.conv1(x))\n",
    "        x2 = self.pool1(x1)\n",
    "\n",
    "        x3 = F.relu(self.conv2(x2))\n",
    "        x4 = F.relu(self.conv3(x3))\n",
    "        x5 = self.pool2(x4)\n",
    "\n",
    "        x6 = F.relu(self.conv4(x5))\n",
    "        x7 = self.global_pool(x6)\n",
    "        x8 = self.fc(x7)\n",
    "\n",
    "        return x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: tensor([[[ 0.5707,  0.5536,  0.5536,  ..., -1.4329, -1.4672, -1.4672],\n",
      "         [ 0.5707,  0.5707,  0.5707,  ..., -1.4500, -1.4843, -1.4843],\n",
      "         [ 0.5707,  0.5707,  0.5707,  ..., -1.4672, -1.4672, -1.4672],\n",
      "         ...,\n",
      "         [ 0.9303,  0.8961,  0.8961,  ...,  0.1939,  0.2282,  0.2453],\n",
      "         [ 0.9303,  0.9303,  0.9474,  ...,  0.1597,  0.1768,  0.2111],\n",
      "         [ 0.9132,  0.9303,  0.9817,  ...,  0.0912,  0.1254,  0.1597]],\n",
      "\n",
      "        [[ 0.7829,  0.7654,  0.7654,  ..., -1.2479, -1.2479, -1.2479],\n",
      "         [ 0.7829,  0.7829,  0.7829,  ..., -1.2654, -1.2654, -1.2654],\n",
      "         [ 0.7829,  0.7829,  0.7829,  ..., -1.2829, -1.2829, -1.2654],\n",
      "         ...,\n",
      "         [ 0.9405,  0.9055,  0.9055,  ...,  0.3978,  0.4328,  0.4503],\n",
      "         [ 0.9405,  0.9230,  0.9580,  ...,  0.3627,  0.3803,  0.4153],\n",
      "         [ 0.9055,  0.9230,  0.9755,  ...,  0.2927,  0.3277,  0.3627]],\n",
      "\n",
      "        [[ 1.0539,  1.0365,  1.0365,  ..., -0.9156, -0.9156, -0.9156],\n",
      "         [ 1.0539,  1.0539,  1.0539,  ..., -0.9330, -0.9330, -0.9330],\n",
      "         [ 1.0539,  1.0539,  1.0539,  ..., -0.9504, -0.9504, -0.9330],\n",
      "         ...,\n",
      "         [ 0.8274,  0.7925,  0.7925,  ...,  0.7751,  0.8099,  0.8274],\n",
      "         [ 0.8448,  0.8274,  0.8622,  ...,  0.7402,  0.7576,  0.7925],\n",
      "         [ 0.8274,  0.8448,  0.8971,  ...,  0.6705,  0.7054,  0.7402]]]), Positive: tensor([[[ 0.5707,  0.5536,  0.5536,  ..., -1.4329, -1.4672, -1.4672],\n",
      "         [ 0.5707,  0.5707,  0.5707,  ..., -1.4500, -1.4843, -1.4843],\n",
      "         [ 0.5707,  0.5707,  0.5707,  ..., -1.4672, -1.4672, -1.4672],\n",
      "         ...,\n",
      "         [ 0.9303,  0.8961,  0.8961,  ...,  0.1939,  0.2282,  0.2453],\n",
      "         [ 0.9303,  0.9303,  0.9474,  ...,  0.1597,  0.1768,  0.2111],\n",
      "         [ 0.9132,  0.9303,  0.9817,  ...,  0.0912,  0.1254,  0.1597]],\n",
      "\n",
      "        [[ 0.7829,  0.7654,  0.7654,  ..., -1.2479, -1.2479, -1.2479],\n",
      "         [ 0.7829,  0.7829,  0.7829,  ..., -1.2654, -1.2654, -1.2654],\n",
      "         [ 0.7829,  0.7829,  0.7829,  ..., -1.2829, -1.2829, -1.2654],\n",
      "         ...,\n",
      "         [ 0.9405,  0.9055,  0.9055,  ...,  0.3978,  0.4328,  0.4503],\n",
      "         [ 0.9405,  0.9230,  0.9580,  ...,  0.3627,  0.3803,  0.4153],\n",
      "         [ 0.9055,  0.9230,  0.9755,  ...,  0.2927,  0.3277,  0.3627]],\n",
      "\n",
      "        [[ 1.0539,  1.0365,  1.0365,  ..., -0.9156, -0.9156, -0.9156],\n",
      "         [ 1.0539,  1.0539,  1.0539,  ..., -0.9330, -0.9330, -0.9330],\n",
      "         [ 1.0539,  1.0539,  1.0539,  ..., -0.9504, -0.9504, -0.9330],\n",
      "         ...,\n",
      "         [ 0.8274,  0.7925,  0.7925,  ...,  0.7751,  0.8099,  0.8274],\n",
      "         [ 0.8448,  0.8274,  0.8622,  ...,  0.7402,  0.7576,  0.7925],\n",
      "         [ 0.8274,  0.8448,  0.8971,  ...,  0.6705,  0.7054,  0.7402]]]), Negative: tensor([[[-0.6794, -0.6794, -0.6452,  ..., -0.2342, -0.2342, -0.2342],\n",
      "         [-0.6623, -0.6452, -0.6109,  ..., -0.2342, -0.2342, -0.2342],\n",
      "         [-0.6281, -0.5938, -0.5253,  ..., -0.2342, -0.2342, -0.2342],\n",
      "         ...,\n",
      "         [-0.4568, -0.4739, -0.4739,  ..., -0.3027, -0.2684, -0.2684],\n",
      "         [-0.4568, -0.4568, -0.4568,  ..., -0.3198, -0.3198, -0.3198],\n",
      "         [-0.4568, -0.4568, -0.4568,  ..., -0.3198, -0.3369, -0.3541]],\n",
      "\n",
      "        [[-0.5651, -0.5651, -0.5301,  ..., -0.1099, -0.1099, -0.1099],\n",
      "         [-0.5476, -0.5301, -0.4951,  ..., -0.1099, -0.1099, -0.1099],\n",
      "         [-0.5126, -0.4776, -0.4076,  ..., -0.1099, -0.1099, -0.1099],\n",
      "         ...,\n",
      "         [-0.3200, -0.3375, -0.3375,  ..., -0.4601, -0.4251, -0.4251],\n",
      "         [-0.3200, -0.3200, -0.3200,  ..., -0.4776, -0.4776, -0.4776],\n",
      "         [-0.3200, -0.3200, -0.3200,  ..., -0.4776, -0.4951, -0.5126]],\n",
      "\n",
      "        [[-0.3404, -0.3404, -0.3055,  ...,  0.1128,  0.1128,  0.1128],\n",
      "         [-0.3230, -0.3055, -0.2707,  ...,  0.1128,  0.1128,  0.1128],\n",
      "         [-0.2881, -0.2532, -0.1835,  ...,  0.1128,  0.1128,  0.1128],\n",
      "         ...,\n",
      "         [-0.1835, -0.2010, -0.2010,  ..., -0.8284, -0.7936, -0.7936],\n",
      "         [-0.1835, -0.1835, -0.1835,  ..., -0.8458, -0.8458, -0.8458],\n",
      "         [-0.1835, -0.1835, -0.1835,  ..., -0.8458, -0.8633, -0.8807]]])\n"
     ]
    }
   ],
   "source": [
    "def GetRandomImage(dataset):\n",
    "    return random.choice(dataset)\n",
    "\n",
    "def Generate_Triplets(dataset):\n",
    "    anchor, anchor_id = GetRandomImage(dataset)\n",
    "\n",
    "    # Find a positive image (same class as anchor)\n",
    "    while True:\n",
    "        positive, positive_id = GetRandomImage(dataset)\n",
    "        if positive_id == anchor_id:\n",
    "            break\n",
    "\n",
    "    # Find a negative image (different class than anchor)\n",
    "    while True:\n",
    "        negative, negative_id = GetRandomImage(dataset)\n",
    "        if negative_id != anchor_id:\n",
    "            break\n",
    "\n",
    "    return anchor, positive, negative\n",
    "\n",
    "anchor, positive, negative = Generate_Triplets(dataset)\n",
    "print(f\"Anchor: {anchor}, Positive: {positive}, Negative: {negative}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
