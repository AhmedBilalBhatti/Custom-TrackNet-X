{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 34 persons, 1 handbag, 367.1ms\n",
      "Speed: 2.0ms preprocess, 367.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'TrackerKCF_create'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m detection \u001b[38;5;129;01min\u001b[39;00m detections:\n\u001b[0;32m     55\u001b[0m     x1, y1, x2, y2, _ \u001b[38;5;241m=\u001b[39m detection\n\u001b[1;32m---> 56\u001b[0m     tracker \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrackerKCF_create\u001b[49m()  \u001b[38;5;66;03m# You can change the tracker type (e.g., KCF, MIL, TLD, etc.)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     trackers\u001b[38;5;241m.\u001b[39mappend(tracker)\n\u001b[0;32m     58\u001b[0m     tracker\u001b[38;5;241m.\u001b[39minit(frame, (\u001b[38;5;28mint\u001b[39m(x1), \u001b[38;5;28mint\u001b[39m(y1), \u001b[38;5;28mint\u001b[39m(x2 \u001b[38;5;241m-\u001b[39m x1), \u001b[38;5;28mint\u001b[39m(y2 \u001b[38;5;241m-\u001b[39m y1)))  \u001b[38;5;66;03m# Initialize tracker\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'TrackerKCF_create'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(r'C:\\Users\\ahmad\\Downloads\\853889-hd_1920_1080_25fps.mp4')\n",
    "\n",
    "# Check if the video file opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video file.\")\n",
    "    exit()\n",
    "\n",
    "# Load the YOLOv8 model and force CPU usage\n",
    "model = YOLO(\"yolov8m.pt\")  # Replace with the path to your YOLOv8 .pt file\n",
    "model.to('cpu')  # Explicitly move the model to CPU\n",
    "\n",
    "# Initialize tracker list (we'll use a list to keep track of individual trackers)\n",
    "trackers = []  # List to store trackers for each object\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture frame.\")\n",
    "        break\n",
    "\n",
    "    # Check if the frame is empty or invalid\n",
    "    if frame is None or frame.size == 0:\n",
    "        print(\"Warning: Empty or invalid frame captured.\")\n",
    "        continue\n",
    "\n",
    "    # Convert the frame to RGB (YOLOv8 expects RGB format)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Run YOLOv8 object detection\n",
    "    results = model(frame_rgb)\n",
    "\n",
    "    # Parse detection results\n",
    "    detections = []  # List to store detected bounding boxes\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes.xyxy.cpu().numpy()  # Get bounding boxes in [x1, y1, x2, y2] format\n",
    "        confidences = result.boxes.conf.cpu().numpy()  # Confidence scores\n",
    "        class_ids = result.boxes.cls.cpu().numpy()  # Class IDs\n",
    "\n",
    "        # Iterate over detections and add them to the detection list\n",
    "        for i, box in enumerate(boxes):\n",
    "            confidence = confidences[i]\n",
    "            if confidence > 0.5:  # Confidence threshold for detection\n",
    "                # Get box coordinates\n",
    "                x1, y1, x2, y2 = box\n",
    "                detections.append([x1, y1, x2, y2, confidence])\n",
    "\n",
    "    # Create new trackers for new detections\n",
    "    for detection in detections:\n",
    "        x1, y1, x2, y2, _ = detection\n",
    "        tracker = cv2.TrackerKCF_create()  # You can change the tracker type (e.g., KCF, MIL, TLD, etc.)\n",
    "        trackers.append(tracker)\n",
    "        tracker.init(frame, (int(x1), int(y1), int(x2 - x1), int(y2 - y1)))  # Initialize tracker\n",
    "\n",
    "    # Update trackers and draw bounding boxes with object IDs\n",
    "    for i, tracker in enumerate(trackers):\n",
    "        success, box = tracker.update(frame)\n",
    "        if success:\n",
    "            x1, y1, w, h = [int(v) for v in box]\n",
    "            cv2.rectangle(frame, (x1, y1), (x1 + w, y1 + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'ID: {i+1}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with bounding boxes and IDs\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Exit if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
